{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andras/miniconda3/envs/rapids-25.02/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import lakeapi\n",
    "import cudf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re, datetime as dt\n",
    "import cudf, cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # ─── 1. PARAMÉTEREK ────────────────────────────────────────────────────────────\n",
    "# start_date = dt.datetime(2025, 2, 15)\n",
    "# end_date   = dt.datetime(2025, 2, 28)\n",
    "# symbol     = \"BTC-USDT\"\n",
    "# exchange   = \"BINANCE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_book = lakeapi.load_data(\n",
    "#     table     = \"book\",\n",
    "#     start     = start_date,\n",
    "#     end       = end_date,\n",
    "#     symbols   = [symbol],\n",
    "#     exchanges = [exchange],\n",
    "# )\n",
    "\n",
    "# # # ─── 3. DINAMIKUS FÁJLNÉV ──────────────────────────────────────────────────────\n",
    "# file_name = (\n",
    "#     f\"data/book_{symbol.lower().replace('-', '_')}_\"\n",
    "#     f\"{start_date:%Y%m%d}_{end_date:%Y%m%d}.parquet\"\n",
    "# )\n",
    "\n",
    "# # # ─── 4. MENTÉS PARQUET-BE cudf használatával ─────────────────────────────────────────\n",
    "# df_book.to_parquet(\n",
    "#     file_name,\n",
    "#     engine=\"pyarrow\",    # cuDF támogatja a pyarrow és fastparquet engine-t\n",
    "#     compression=\"snappy\",\n",
    "# )\n",
    "\n",
    "# print(f\"Mentés kész: {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_report(\n",
    "        symbol: str,\n",
    "        start_date: str | dt.datetime,\n",
    "        end_date:   str | dt.datetime,\n",
    "        data_dir: str = \"./data\",\n",
    "        cols: tuple[str,...] = (\"origin_time\", \"received_time\"),\n",
    "):\n",
    "    \"\"\"Fájl-streamelt min/max + gap statisztika – max. 1 fájl a GPU-n\"\"\"\n",
    "\n",
    "    # ---- előkészítés -------------------------------------------------------\n",
    "    sym_pat = symbol.lower().replace(\"-\", \"_\")\n",
    "    rex = re.compile(rf\"book_{sym_pat}_(\\d{{8}})_(\\d{{8}})\\.parquet$\")\n",
    "    sd = pd.to_datetime(start_date)\n",
    "    ed = pd.to_datetime(end_date)\n",
    "\n",
    "    # ---- globális statok (inkrementálisan frissítjük) ----------------------\n",
    "    min_o = max_o = min_r = max_r = None\n",
    "    rec_cnt = 0\n",
    "    largest_gap = pd.Timedelta(0)\n",
    "    largest_gap_start = None\n",
    "    missing_secs = set()\n",
    "\n",
    "    # ---- stream feldolgozás fájlról fájlra ---------------------------------\n",
    "    for fn in sorted(os.listdir(data_dir)):\n",
    "        m = rex.match(fn)\n",
    "        if not m:\n",
    "            continue\n",
    "        f_sd = pd.to_datetime(m.group(1))\n",
    "        f_ed = pd.to_datetime(m.group(2))\n",
    "        if f_ed < sd or f_sd > ed:\n",
    "            continue\n",
    "\n",
    "        fp = os.path.join(data_dir, fn)\n",
    "        df = cudf.read_parquet(fp, columns=cols, engine=\"cudf\")\n",
    "\n",
    "        # ↓↓↓   csak a kért dátumtartomány\n",
    "        df = df[\n",
    "            (df[\"received_time\"] >= sd) &\n",
    "            (df[\"received_time\"] <= ed)\n",
    "        ]\n",
    "\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        # ------- min / max frissítés ---------------------------------------\n",
    "        o_min, o_max = df[\"origin_time\"].min(),   df[\"origin_time\"].max()\n",
    "        r_min, r_max = df[\"received_time\"].min(), df[\"received_time\"].max()\n",
    "\n",
    "        min_o = o_min if min_o is None else min(min_o, o_min)\n",
    "        max_o = o_max if max_o is None else max(max_o, o_max)\n",
    "        min_r = r_min if min_r is None else min(min_r, r_min)\n",
    "        max_r = r_max if max_r is None else max(max_r, r_max)\n",
    "\n",
    "        # ------- gaps a received_time alapján ------------------------------\n",
    "        recv_sorted = df[\"received_time\"].sort_values().to_pandas()\n",
    "        gaps = recv_sorted.diff().dropna()\n",
    "        if not gaps.empty and gaps.max() > largest_gap:\n",
    "            largest_gap = gaps.max()\n",
    "            largest_gap_start = recv_sorted.iloc[gaps.argmax()]\n",
    "\n",
    "        # ------- hiányzó másodpercek (set-union) ---------------------------\n",
    "        secs = recv_sorted.dt.floor(\"s\").unique()\n",
    "        missing_secs.update(\n",
    "            pd.date_range(secs.min(), secs.max(), freq=\"s\").difference(secs)\n",
    "        )\n",
    "\n",
    "        rec_cnt += len(df)\n",
    "\n",
    "        # ------- memória felszabadítás GPU-n -------------------------------\n",
    "        del df\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "    # ---- report ------------------------------------------------------------\n",
    "    dur_r = (max_r - min_r) / np.timedelta64(1, \"s\") if rec_cnt else 0\n",
    "    print(f\"\"\"\n",
    "[GPU stream report]   {symbol}\n",
    "    idősáv: {sd}  →  {ed}\n",
    "\n",
    "Origin_time:   {min_o}  →  {max_o}\n",
    "Received_time: {min_r}  →  {max_r}\n",
    "Records: {rec_cnt:,}\n",
    "Avg rec/s: {rec_cnt/dur_r:.2f}\n",
    "\n",
    "Largest gap: {largest_gap/np.timedelta64(1,'s'):.2f} s\n",
    "Gap start  : {largest_gap_start}\n",
    "\n",
    "Missing whole seconds: {len(missing_secs):,}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[GPU stream report]   BTC-USDT\n",
      "    idősáv: 2024-11-15 00:00:00  →  2025-02-28 00:00:00\n",
      "\n",
      "Origin_time:   1970-01-01T00:00:00.000000000  →  2025-02-27T23:59:59.914000128\n",
      "Received_time: 2024-11-15T00:00:00.017741312  →  2025-02-27T23:59:59.916363776\n",
      "Records: 55,555,373\n",
      "Avg rec/s: 6.12\n",
      "\n",
      "Largest gap: 164.30 s\n",
      "Gap start  : 2024-11-25 16:36:30.217062912\n",
      "\n",
      "Missing whole seconds: 1,678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "quality_report(\n",
    "        symbol=\"BTC-USDT\",\n",
    "        start_date=dt.datetime(2024,11,15),\n",
    "        end_date  =dt.datetime(2025, 2,28),\n",
    "        data_dir  =\"./data\",\n",
    "        cols = [\"received_time\", \"origin_time\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cudf-el hosszabb időszakokra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fair_mid_imbalance(\n",
    "        symbol: str,\n",
    "        start_date: dt.date | dt.datetime | str,\n",
    "        end_date:   dt.date | dt.datetime | str,\n",
    "        data_dir:   str = \"./data\",\n",
    "        N:          int = 20,        # depth\n",
    "        row_batch:  int = 500_000,   # batch-méret\n",
    ") -> cudf.DataFrame:\n",
    "    \"\"\"\n",
    "    Visszaad egy cuDF-et kizárólag a szükséges feature-ökkel:\n",
    "        time | fair | mid | imbalance\n",
    "    minden tickre, a megadott időintervallumban.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- segítség: string → datetime --------------------------------------\n",
    "    def _to_dt(x):\n",
    "        if isinstance(x, str):\n",
    "            return dt.datetime.fromisoformat(x)\n",
    "        if isinstance(x, dt.date) and not isinstance(x, dt.datetime):\n",
    "            return dt.datetime.combine(x, dt.time.min)\n",
    "        return x\n",
    "    sd, ed = _to_dt(start_date), _to_dt(end_date)\n",
    "\n",
    "    sym = symbol.lower().replace(\"-\", \"_\")\n",
    "    rex = re.compile(rf\"book_{sym}_(\\d{{8}})_(\\d{{8}})\\.parquet$\")\n",
    "\n",
    "    price_cols = [f\"{side}_{i}_price\" for side in (\"bid\", \"ask\") for i in range(N)]\n",
    "    size_cols  = [f\"{side}_{i}_size\"  for side in (\"bid\", \"ask\") for i in range(N)]\n",
    "    keep_cols  = [\"received_time\"] + price_cols + size_cols\n",
    "\n",
    "    # -------- batch-kalkuláció --------------------------------------------\n",
    "    def _calc(frame: cudf.DataFrame) -> cudf.DataFrame:\n",
    "        # fair\n",
    "        vamp, denom = 0.0, 0.0\n",
    "        for p, s in zip(price_cols, size_cols):\n",
    "            w     = frame[p] * frame[s]\n",
    "            vamp += w\n",
    "            denom+= frame[s]\n",
    "        fair = vamp / denom\n",
    "        mid  = (frame[\"bid_0_price\"] + frame[\"ask_0_price\"]) / 2\n",
    "\n",
    "        # imbalance: (sum bid_size – sum ask_size) / total_depth\n",
    "        depth_bid = sum(frame[f\"bid_{i}_size\"] for i in range(N))\n",
    "        depth_ask = sum(frame[f\"ask_{i}_size\"] for i in range(N))\n",
    "        total_depth = depth_bid + depth_ask\n",
    "        imb = (depth_bid - depth_ask) / total_depth.replace(0, cp.nan)  # elkerüljük a 0-osztást\n",
    "\n",
    "        return cudf.DataFrame({\n",
    "            \"time\": frame[\"received_time\"],\n",
    "            \"fair\": fair.astype(\"float32\"),\n",
    "            \"mid\" : mid .astype(\"float32\"),\n",
    "            \"imb\" : imb .astype(\"float32\"),\n",
    "        })\n",
    "\n",
    "    chunks = []\n",
    "\n",
    "    # -------- fájl-stream --------------------------------------------------\n",
    "    for fn in sorted(os.listdir(data_dir)):\n",
    "        m = rex.match(fn)\n",
    "        if not m:                       # nem passzol a mintára\n",
    "            continue\n",
    "        f_sd = dt.datetime.strptime(m.group(1), \"%Y%m%d\")\n",
    "        f_ed = dt.datetime.strptime(m.group(2), \"%Y%m%d\")\n",
    "        if f_ed < sd or f_sd > ed:      # nem metszik az intervallumot\n",
    "            continue\n",
    "\n",
    "        gdf = cudf.read_parquet(\n",
    "            os.path.join(data_dir, fn),\n",
    "            columns = keep_cols,\n",
    "            engine  = \"cudf\"\n",
    "        )\n",
    "        # idősáv-szűrés\n",
    "        gdf = gdf[(gdf[\"received_time\"] >= sd) & (gdf[\"received_time\"] <= ed)]\n",
    "        if gdf.empty: continue\n",
    "\n",
    "        # downcast float32\n",
    "        for c in price_cols + size_cols:\n",
    "            gdf[c] = gdf[c].astype(\"float32\")\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "        # batch-feldolgozás\n",
    "        if len(gdf) > row_batch:\n",
    "            for i in range(0, len(gdf), row_batch):\n",
    "                chunk = _calc(gdf.iloc[i:i+row_batch])\n",
    "                chunks.append(chunk)\n",
    "                cp.get_default_memory_pool().free_all_blocks()\n",
    "        else:\n",
    "            chunks.append(_calc(gdf))\n",
    "            cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "    return cudf.concat(chunks, ignore_index=True) if chunks else \\\n",
    "           cudf.DataFrame(columns=[\"time\",\"fair\",\"mid\",\"imb\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           time          fair           mid       imb\n",
      "0 2024-11-15 00:00:00.017741312  87325.171875  87325.593750  0.025857\n",
      "1 2024-11-15 00:00:01.967001600  87326.820312  87325.593750 -0.225982\n",
      "2 2024-11-15 00:00:02.339866624  87320.484375  87321.625000 -0.018794\n",
      "3 2024-11-15 00:00:02.517839360  87320.203125  87318.164062 -0.611143\n",
      "4 2024-11-15 00:00:02.805629952  87309.242188  87307.890625 -0.265398\n"
     ]
    }
   ],
   "source": [
    "fm_cu = load_fair_mid_imbalance(\n",
    "    symbol     = \"BTC-USDT\",\n",
    "    start_date = dt.datetime(2024,11,15),\n",
    "    end_date   = dt.datetime(2025, 2,28),\n",
    "    data_dir   = \"./data\",\n",
    "    N          = 20,\n",
    "    row_batch  = 400_000\n",
    ")\n",
    "\n",
    "print(fm_cu.head())\n",
    "# time | fair | mid | imb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Szórás alapú threshold - elévült"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np, pandas as pd, cudf\n",
    "\n",
    "# def trading_pnl_realtime(\n",
    "#         fm_cu,                   # fair–mid DataFrame (cuDF vagy pandas)\n",
    "#         book_df,                 # teljes order-book  (pandas)\n",
    "#         window=\"24h\",\n",
    "#         price_col=\"bid_0_price\",\n",
    "#         return_trade_log=False\n",
    "# ):\n",
    "#     # ---- 0) normalizálás pandasra, rendezés ---------------------------------\n",
    "#     fm = fm_cu.to_pandas() if isinstance(fm_cu, cudf.DataFrame) else fm_cu.copy()\n",
    "#     fm[\"time\"]   = pd.to_datetime(fm[\"time\"], errors=\"coerce\")\n",
    "#     fm = fm.dropna(subset=[\"time\", \"fair\", \"mid\"]).sort_values(\"time\")\n",
    "#     fm[\"signal\"] = fm[\"fair\"] - fm[\"mid\"]\n",
    "\n",
    "#     # ---- 1) SOR-alapú rolling σ  -------------------------------------------\n",
    "#     N = int(6 * pd.Timedelta(window).total_seconds())      # ≈ 6 tick/sec * window\n",
    "#     fm[\"thr\"] = (\n",
    "#         fm[\"signal\"]\n",
    "#           .rolling(window=N, min_periods=N, closed=\"left\")\n",
    "#           .std(ddof=0)\n",
    "#     )\n",
    "\n",
    "#     # ---- 2) Benchmark return ugyanebből az időtartományból -----------------\n",
    "#     trading_start = fm[\"time\"].min() + pd.Timedelta(window)\n",
    "#     trading_end   = fm[\"time\"].max()\n",
    "\n",
    "#     bench_slice = book_df[book_df[\"received_time\"] >= trading_start]\n",
    "#     bench_ret   = np.nan if bench_slice.empty else (\n",
    "#         bench_slice[price_col].iloc[-1] / bench_slice[price_col].iloc[0]\n",
    "#     )\n",
    "\n",
    "#     # ---- 3) Pozíció-séta ----------------------------------------------------\n",
    "#     pos = 0; entry = None; cum_ret = 1.0; trades = 0; log = []\n",
    "#     for ts, row in fm.iterrows():\n",
    "#         thr   = row.thr\n",
    "#         if np.isnan(thr) or thr == 0:\n",
    "#             continue\n",
    "\n",
    "#         sig, price = row.signal, row.mid\n",
    "\n",
    "#         if pos == 0:                               # flat  →  entry\n",
    "#             if sig >  thr:\n",
    "#                 pos, entry, trades =  1, price, trades+1\n",
    "#                 log.append((ts, \"enter_long\",  price, np.nan))\n",
    "#             elif sig < -thr:\n",
    "#                 pos, entry, trades = -1, price, trades+1\n",
    "#                 log.append((ts, \"enter_short\", price, np.nan))\n",
    "\n",
    "#         elif pos == 1 and sig < -thr:              # long → flat\n",
    "#             ret       = (price-entry)/entry\n",
    "#             cum_ret  *= 1 + ret\n",
    "#             trades   += 1\n",
    "#             log.append((ts, \"exit_long\",  price, ret))\n",
    "#             pos, entry = 0, None\n",
    "\n",
    "#         elif pos == -1 and sig >  thr:             # short → flat\n",
    "#             ret       = (entry-price)/entry\n",
    "#             cum_ret  *= 1 + ret\n",
    "#             trades   += 1\n",
    "#             log.append((ts, \"exit_short\", price, ret))\n",
    "#             pos, entry = 0, None\n",
    "\n",
    "#     trade_log = (\n",
    "#         pd.DataFrame(log, columns=[\"time\", \"action\", \"price\", \"ret\"])\n",
    "#         if return_trade_log else None\n",
    "#     )\n",
    "\n",
    "#     # ---- 4) sigma_df most már thr és signal oszloppal ----------------------\n",
    "#     sigma_df = fm[[\"time\", \"thr\", \"signal\"]].copy()\n",
    "\n",
    "#     # ▼────────────────────────  DIAG: thr NaN-arány  ────────────────────────\n",
    "#     period_mask = (sigma_df[\"time\"] >= trading_start) & (sigma_df[\"time\"] <= trading_end)\n",
    "#     nan_ratio   = sigma_df.loc[period_mask, \"thr\"].isna().mean()\n",
    "#     print(f\"thr NaN aránya a kereskedési időszakban: {nan_ratio:6.2%}\")\n",
    "#     # ▲────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "#     return cum_ret, trades, bench_ret, trade_log, sigma_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cum_ret, n_trades, bench_ret, trade_log, sigma_df = trading_pnl_realtime(\n",
    "#     fm, df_book, window=\"24h\", return_trade_log=True\n",
    "# )\n",
    "\n",
    "# print(f\"Stratégia hozam:     {cum_ret: .4f}×\")\n",
    "# print(f\"Benchmark (bid₀):    {bench_ret: .4f}×\")\n",
    "# print(f\"Trade-ek száma:      {n_trades}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Szórás alapú threshold ellenőrzése"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1) Extrém ret-ek listája\n",
    "# extreme = trade_log[trade_log.ret.abs() > 0.2]\n",
    "# print(\"Extrém ret-ek száma:\", len(extreme))\n",
    "# display(extreme.head())\n",
    "\n",
    "# # 2) Trades / másodperc\n",
    "# trade_log['time'] = pd.to_datetime(trade_log['time'])\n",
    "# trade_log['sec']  = trade_log['time'].dt.floor('S')\n",
    "# print(\"Átlag trades/sec:\", trade_log.groupby('sec').size().mean())\n",
    "\n",
    "# # 3) Threshold stat\n",
    "# thr_stats = sigma_df['thr'].describe()\n",
    "# print(\"\\n--- Threshold statisztika ---\")\n",
    "# print(thr_stats)\n",
    "\n",
    "# # 4) Jelek mekkora része lépi át közvetlenül a thr-t?\n",
    "# #   (itt nincs 2*thr, csak abs(signal)>thr)\n",
    "# df_active = sigma_df.dropna(subset=['thr','signal'])\n",
    "# ratio    = (df_active['signal'].abs() > df_active['thr']).mean()\n",
    "# print(f\"\\nA jel {ratio:.2%}-ában lépi át a thr-t\")\n",
    "\n",
    "# # Példa: feltételezzük, hogy sigma_df létezik és tartalmazza a 'time' és a 'thr' oszlopokat.\n",
    "\n",
    "# # 1) Perc alapú csoportosítás: lekerekítjük a timestampeket percre\n",
    "# sigma_df['minute'] = sigma_df['time'].dt.floor('T')\n",
    "\n",
    "# # 2) Kiszűrjük azokat a perceket, ahol a thr nem NaN\n",
    "# valid_minutes = (\n",
    "#     sigma_df.loc[sigma_df['thr'].notna(), 'minute']\n",
    "#     .drop_duplicates()\n",
    "#     .sort_values()\n",
    "#     .reset_index(drop=True)\n",
    "# )\n",
    "\n",
    "# # 3) Keresünk folyamatos futamokat (egymást követő percek)\n",
    "# intervals = []\n",
    "# if not valid_minutes.empty:\n",
    "#     start = valid_minutes.iloc[0]\n",
    "#     prev  = start\n",
    "#     for current in valid_minutes.iloc[1:]:\n",
    "#         if current - prev == pd.Timedelta('1T'):\n",
    "#             prev = current\n",
    "#         else:\n",
    "#             intervals.append((start, prev))\n",
    "#             start = current\n",
    "#             prev  = current\n",
    "#     intervals.append((start, prev))\n",
    "\n",
    "# # 4) Kiíratás\n",
    "# print(\"Threshold aktív intervallumok (percre aggregálva):\")\n",
    "# for s, e in intervals:\n",
    "#     print(f\"  • {s} → {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf, cupy as cp, pandas as pd\n",
    "\n",
    "def extract_extremes_ticks(\n",
    "        fm_cu,                    # cuDF vagy pandas – 'time' + ár\n",
    "        window=\"24h\",             # rolling ablak hossza\n",
    "        q=0.99,                   # felső kvantilis (pl. 0.995 → 0.5-0.5 %)\n",
    "        price_col=\"fair\",\n",
    "        tick_per_sec=6.0          # átlag tick/s (ha pontos értéket tudsz, add meg)\n",
    "):\n",
    "    \"\"\"\n",
    "    Tick-szintű extrém pontok (top / bottom) visszaadása.\n",
    "\n",
    "    Visszatér: pandas DataFrame ['time','price','zone'] ahol zone ∈ {'top','bottom'}\n",
    "    \"\"\"\n",
    "    # -- 0) cuDF-re, rendezés ------------------------------------------------\n",
    "    gdf = fm_cu if isinstance(fm_cu, cudf.DataFrame) else cudf.from_pandas(fm_cu)\n",
    "    gdf = gdf[[\"time\", price_col]].copy()\n",
    "    gdf[\"time\"] = cudf.to_datetime(gdf[\"time\"])\n",
    "    gdf         = gdf.sort_values(\"time\")\n",
    "\n",
    "    # -- 1) rolling kvantilis tick-szinten ----------------------------------\n",
    "    N = int(pd.Timedelta(window).total_seconds() * tick_per_sec)\n",
    "\n",
    "    def _q(arr, qq):\n",
    "        return cp.nanquantile(cp.asarray(arr, dtype=cp.float32), qq)\n",
    "\n",
    "    try:   # ***** GPU *****\n",
    "        gdf[\"top\"] = (\n",
    "            gdf[price_col].rolling(window=N, min_periods=N)\n",
    "                           .apply(_q, raw=True, args=(q,))\n",
    "        )\n",
    "        gdf[\"bot\"] = (\n",
    "            gdf[price_col].rolling(window=N, min_periods=N)\n",
    "                           .apply(_q, raw=True, args=(1-q,))\n",
    "        )\n",
    "    except Exception:\n",
    "        # ***** CPU fallback – kicsi a többlet-idő *****\n",
    "        pdf = gdf.to_pandas()\n",
    "        pdf[\"top\"] = pdf[price_col].rolling(N, min_periods=N).quantile(q)\n",
    "        pdf[\"bot\"] = pdf[price_col].rolling(N, min_periods=N).quantile(1-q)\n",
    "        gdf = cudf.from_pandas(pdf)\n",
    "\n",
    "    # -- 2) zone + szűrés ----------------------------------------------------\n",
    "    gdf[\"zone\"] = \"mid\"\n",
    "    m_top       = gdf[price_col] >= gdf[\"top\"]\n",
    "    m_bot       = gdf[price_col] <= gdf[\"bot\"]\n",
    "    gdf.loc[m_top, \"zone\"] = \"top\"\n",
    "    gdf.loc[m_bot, \"zone\"] = \"bottom\"\n",
    "\n",
    "    extremes = gdf.loc[m_top | m_bot, [\"time\", price_col, \"zone\"]]  \\\n",
    "                  .rename(columns={price_col: \"price\"})\n",
    "\n",
    "    return extremes.to_pandas().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           time         price zone\n",
      "0 2024-11-15 20:49:27.616990720  91215.757812  top\n",
      "1 2024-11-15 20:49:27.718318080  91220.875000  top\n",
      "2 2024-11-15 20:49:27.816460288  91221.257812  top\n",
      "3 2024-11-15 20:49:28.019159296  91223.093750  top\n",
      "4 2024-11-15 20:49:28.116102912  91222.773438  top\n"
     ]
    }
   ],
   "source": [
    "ext = extract_extremes_ticks(\n",
    "    fm_cu     = fm_cu,          # tick-szintű fair-mid cuDF\n",
    "    window    = \"24h\",\n",
    "    q         = 0.99998,       # felső 0.5 %  / alsó 0.5 %\n",
    "    price_col = \"fair\",\n",
    "    tick_per_sec = 6.12      # vagy amit a statisztikád mutat\n",
    ")\n",
    "\n",
    "print(ext.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 0) Idő szerint rendezés (ha még nem) ----------------------------\n",
    "fm_cu = fm_cu.sort_values(\"time\")\n",
    "\n",
    "# --- 1) spread = mid − fair  (float32, hogy kíméljük a memóriát) ------\n",
    "fm_cu[\"spread\"] = (fm_cu[\"mid\"] - fm_cu[\"fair\"]).astype(\"float32\")\n",
    "\n",
    "# --- 2) 1-perces rolling σ  ------------------------------------------\n",
    "#     (≈ 60 s × 6 tick/s  →  360 tick ablak)\n",
    "N = 60 * 6                # 360\n",
    "fm_cu[\"sigma\"] = (\n",
    "    fm_cu[\"spread\"]\n",
    "      .rolling(window=N, min_periods=N)\n",
    "      .std(ddof=0)         # ddof=0, ugyanúgy mint a pandas-példában\n",
    "      .astype(\"float32\")\n",
    ")\n",
    "\n",
    "# --- 3) distance_to_fair  --------------------------------------------\n",
    "fm_cu[\"dist_to_fair\"] = fm_cu[\"spread\"] / fm_cu[\"sigma\"]\n",
    "\n",
    "#   (ha a 0-s szórások miatt végtelenek/NaN-ok jönnének létre, kezelheted:)\n",
    "fm_cu[\"dist_to_fair\"] = fm_cu[\"dist_to_fair\"].fillna(0).replace([cp.inf, -cp.inf], 0)\n",
    "\n",
    "# --- 4) 'imb' már benne volt; semmi konverzió nem kell ---------------\n",
    "\n",
    "# (opcionális) a temp 'spread' oszlopot törölheted\n",
    "# fm_cu = fm_cu.drop_columns(\"spread\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         column  missing_%           min            p1          p99  \\\n",
      "0          time   0.000000          <NA>          <NA>         <NA>   \n",
      "1          fair   0.000000   82258.15625   86436.82617    106628.06   \n",
      "2           mid   0.000000   82256.01563      86436.78     106628.0   \n",
      "3           imb   0.000000  -0.999823332  -0.986059854  0.986911363   \n",
      "4        spread   0.000000   -903.546875     -2.609375    2.6015625   \n",
      "5         sigma   0.000646   0.004667363    0.03304407  2.636027441   \n",
      "6  dist_to_fair   0.000000   -101.365921  -3.490539446  3.527764509   \n",
      "\n",
      "           max  \n",
      "0         <NA>  \n",
      "1  109583.5156  \n",
      "2  109574.7656  \n",
      "3  0.999962807  \n",
      "4    765.15625  \n",
      "5  155.2344666  \n",
      "6  76.98890686  \n"
     ]
    }
   ],
   "source": [
    "def columnwise_minmax_pct_cu(df_cu: cudf.DataFrame,\n",
    "                             p_low: float = 0.01,\n",
    "                             p_high: float = 0.99,\n",
    "                             sample: int | None = None) -> cudf.DataFrame:\n",
    "    \"\"\"\n",
    "    missing_% | min | p_low | p_high | max   minden oszlopra, cuDF-ben.\n",
    "    Igény szerint mintavételez: ha sample!=None és a sorok száma > sample,\n",
    "    előbb `.sample(sample, random_state=0)`-t vesz a kvantilishez.\n",
    "    \"\"\"\n",
    "    rows, cols = [], []\n",
    "    for col in df_cu.columns:\n",
    "        s = df_cu[col]\n",
    "        miss = float(s.isna().mean() * 100)\n",
    "\n",
    "        if cudf.api.types.is_numeric_dtype(s.dtype):\n",
    "            # opcionális mintavétel kvantilishez\n",
    "            s_q = s.sample(sample, random_state=0) if sample and len(s) > sample else s\n",
    "\n",
    "            q = s_q.quantile([p_low, p_high])      # mini-cuDF\n",
    "            lo, hi = float(q.iloc[0]), float(q.iloc[1])\n",
    "\n",
    "            mn = float(s.min())\n",
    "            mx = float(s.max())\n",
    "            row = [miss, mn, lo, hi, mx]\n",
    "        else:\n",
    "            row = [miss, None, None, None, None]\n",
    "\n",
    "        rows.append(row)\n",
    "        cols.append(col)\n",
    "\n",
    "        # GPU-memória takarítás\n",
    "        del s\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "    out = cudf.DataFrame(rows,\n",
    "            columns=[\"missing_%\", \"min\",\n",
    "                     f\"p{int(p_low*100)}\", f\"p{int(p_high*100)}\", \"max\"])\n",
    "    out.insert(0, \"column\", cols)          # hogy legyen oszlopnév is\n",
    "    return out\n",
    "\n",
    "\n",
    "# --- hívás ---------------------------------------------------------------\n",
    "report_cu = columnwise_minmax_pct_cu(fm_cu, p_low=0.01, p_high=0.99, sample=1_000_000)\n",
    "\n",
    "print(report_cu)         # továbbra is cuDF, marad GPU-n\n",
    "# ha CPU-n szeretnéd nézni:\n",
    "# print(report_cu.to_pandas().head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ price_extremes_20241115_20250227.html elkészült\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import cudf\n",
    "\n",
    "# ―――――――――――――――――――――――――――――――――――――――――――――――――\n",
    "# 0) fm és ext biztos pandas DataFrame\n",
    "if isinstance(fm_cu, cudf.DataFrame):\n",
    "    fm_pdf = fm_cu.to_pandas()\n",
    "else:\n",
    "    fm_pdf = fm_cu.copy()\n",
    "\n",
    "if isinstance(ext, cudf.DataFrame):\n",
    "    ext_pdf = ext.to_pandas()\n",
    "else:\n",
    "    ext_pdf = ext.copy()\n",
    "\n",
    "# ―――――――――――――――――――――――――――――――――――――――――――――――――\n",
    "# 1) perc-átlagolt ár (price_min)\n",
    "price_min = (\n",
    "    fm_pdf[[\"time\", \"fair\"]]\n",
    "      .assign(time=lambda df: pd.to_datetime(df[\"time\"]).dt.floor(\"min\"))\n",
    "      .groupby(\"time\", as_index=False)[\"fair\"].mean()\n",
    "      .rename(columns={\"fair\": \"price\"})\n",
    "      .sort_values(\"time\")\n",
    ")\n",
    "\n",
    "# ―――――――――――――――――――――――――――――――――――――――――――――――――\n",
    "# 2) extrémek perc-re kerekítve (ext_min)\n",
    "ext_min = (\n",
    "    ext_pdf[[\"time\", \"zone\"]]\n",
    "      .assign(time=lambda df: pd.to_datetime(df[\"time\"]).dt.floor(\"min\"))\n",
    "      .drop_duplicates(\"time\")\n",
    ")\n",
    "\n",
    "# ―――――――――――――――――――――――――――――――――――――――――――――――――\n",
    "# 3) merge + alap zone = 'mid'\n",
    "price_min = price_min.merge(ext_min, on=\"time\", how=\"left\")\n",
    "price_min[\"zone\"] = price_min[\"zone\"].fillna(\"mid\")\n",
    "\n",
    "# ―――――――――――――――――――――――――――――――――――――――――――――――――\n",
    "# 4) Plotly-ábra\n",
    "fig = make_subplots(rows=1, cols=1, shared_xaxes=True)\n",
    "\n",
    "# 4.a) háttér: teljes perces árfolyam\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=price_min[\"time\"], y=price_min[\"price\"],\n",
    "    mode=\"lines\",\n",
    "    line=dict(color=\"rgba(130,130,130,0.35)\", width=1),\n",
    "    hoverinfo=\"skip\", showlegend=False\n",
    "))\n",
    "\n",
    "# 4.b) extrém szakaszok: top=zöld, bottom=piros\n",
    "cmap      = {\"top\": \"seagreen\", \"bottom\": \"firebrick\"}\n",
    "is_extrem = price_min[\"zone\"] != \"mid\"\n",
    "grp_idx   = (is_extrem != is_extrem.shift()).cumsum()\n",
    "\n",
    "for _, seg in price_min[is_extrem].groupby(grp_idx):\n",
    "    z = seg[\"zone\"].iat[0]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=seg[\"time\"], y=seg[\"price\"],\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=cmap[z], width=1.6),\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "# 5) tengelyek, layout\n",
    "fig.update_yaxes(title_text=\"Price\")\n",
    "fig.update_layout(\n",
    "    height=600, width=950,\n",
    "    hovermode=\"x unified\",\n",
    "    template=\"simple_white\"\n",
    ")\n",
    "\n",
    "# ―――――――――――――――――――――――――――――――――――――――――――――――――\n",
    "# 6) dátumok kinyerése és HTML mentés névvel\n",
    "start_str = price_min[\"time\"].min().strftime(\"%Y%m%d\")\n",
    "end_str   = price_min[\"time\"].max().strftime(\"%Y%m%d\")\n",
    "filename  = f\"price_extremes_{start_str}_{end_str}.html\"\n",
    "\n",
    "fig.write_html(filename, include_plotlyjs=\"cdn\")\n",
    "print(f\"✔ {filename} elkészült\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-25.02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
